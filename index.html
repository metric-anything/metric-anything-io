<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MetricAnything: Scaling Metric Depth Pretraining with Noisy
        Heterogeneous Sources</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>
    <style>
        /* Placeholder background for missing thumbnail images */
        .thumbnail-item img[src*="placeholder"] {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            object-fit: cover;
        }

        .thumbnail-item img {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        }

        iframe {
        border-radius: 0.5em;
        width: 27.5em;
        height: 27.5em;
        border: none;
        box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
        }
        @media (max-width: 768px) {
        iframe {
            width: 100%;
            height: 30em;
        }
        }

        #architecture-img {
        width: 90%;
        margin: 0 auto;
        display: block;
        border: none;
        border-radius: 0; /* removed border radius */
        box-shadow: none; /* removed box shadow */
        }

    </style>

    <!-- 导航栏 -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <h2>MetricAnything</h2>
            </div>
            <div class="nav-links">
                <a href="#overview">Overview</a>
                <a href="#pipeline">Pipeline</a>
                <a href="#results">Results</a>
                <a href="#comparison">Comparison</a>
                <a href="#interactive-examples">Demo</a>
                <a href="#citation">Citation</a>
            </div>
        </div>
    </nav>

    <!-- Banner 区域 -->
    <section class="banner">
        <div class="banner-content">
            <div class="banner-text">
                <h2 class="banner-title">MetricAnything</h2>
                <h3 class="banner-subtitle">Scaling Metric Depth Pretraining with Noisy
                    Heterogeneous Sources</h3>
                <div class="authors">
                    <a href="https://mabaorui.github.io/" target="_blank" >Baorui Ma<sup>*&sect;</sup></a>,
                    <a href="" target="_blank">Jiahui Yang<sup>*</sup></a>,
                    <a href="https://scholar.google.com/citations?user=L8tcNioAAAAJ&hl=en" target="_blank">Donglin Di<sup>&dagger;</sup></a>,
                    <a href="https://scholar.google.com/citations?user=gGAoxSAAAAAJ&hl=en" target="_blank">Xuancheng Zhang<sup></sup></a>,
                    <a href="" target="_blank">Jianxun Cui</a>,
                    <a href="" target="_blank">Hao Li</a>,
                    <a href="" target="_blank">Xie Yan</a>,
                    <a href="" target="_blank">Wei Chen</a>,
                    <br><br>
                    &dagger;Proejct Lead, *Equal Contribution, &sect;Corresponding Author
                </div>

                <div class="banner-links">
                    <a href="./assets/MetricAnything.pdf" target="_blank" class="link-btn">
                        <i class="fas fa-file-pdf"></i> Tech Report
                    </a>
                    <a href="" target="_blank" class="link-btn">
                        <i class="fas fa-graduation-cap"></i> arXiv
                    </a>
                    <a href="" target="_blank" class="link-btn">
                        <i class="fas fa-rocket"></i> Demo (Coming Soon)
                    </a>
                    <a href="https://github.com/metric-anything/metric-anything" target="_blank" class="link-btn">
                        <i class="fab fa-github"></i> Code
                    </a>
                </div>
            </div>
        </div>
    </section>

    
    <section class="main-demo">
        <div class="container">
            <div class="tldr-content">
                <p>
                    <i class="fas fa-bolt"></i> <strong>TL;DR:</strong> 
                    
                    Metric Anything: First to demonstrate clear scaling trends in metric depth estimation. Uses Sparse Metric Prompt (randomly masked depth maps) to decouple spatial reasoning from sensor biases, trained on ~20M image-depth pairs. The pretrained model excels at depth completion, super-resolution, and radar-camera fusion, while its distilled prompt-free student achieves SOTA on 7 downstream tasks including monocular depth estimation, camera intrinsics recovery, multi-view 3D reconstruction, and VLA planning.
                    
                </p>
            </div>
            <div class="demo-video-container">
                <!-- Loading Indicator -->
                <!-- Main Video -->
                    <div class="demo-video-container">
                            <div class="hero-body">
                              <video id="teaser" 
                                class="main-video lazy-video" 
                                controls playsinline height="40%">

                                <source src="./assets/video/ready/1-teaser.mp4" type="video/mp4">
                              </video>
                            </div>

                    </div>

            </div>
        </div>
    </section>

    <!-- Abstract -->
    <section id="overview" class="abstract" style="text-align: left;">
        <div class="container">
            <div class="abstract-content" style="text-align: left;">
                <h3><i class="fas fa-file-alt"></i> Abstract</h3>
                <p>Scaling has powered recent advances in vision foundation models; however, extending this paradigm to metric depth estimation remains 
                challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce 
                <strong>Metric Anything</strong>, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources 
                without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the <strong>Sparse 
                  Metric Prompt</strong>, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from 
                  sensor and camera biases. Using ∼20M image–depth pairs spanning reconstructed, captured, and rendered 3D data across 10,000+ camera models, 
                  we demonstrate—for the first time—a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such 
                  as depth completion, super-resolution, and radar–camera fusion, while its distilled prompt-free student achieves state-of-the-art results on 
                  monocular depth estimation, camera intrinsics recovery, single- and multi-view metric 3D reconstruction, and VLA planning. We also show that 
                  using the pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities 
                  in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, 
                  establishing a new path toward scalable and efficient real-world metric perception.</p>

                </section>
            </div>
            
        </div>
    </section>

    <!-- Pipeline -->
    <section id="pipeline" class="pipline" style="text-align: left;">
        <div class="container">
            <div class="abstract-content" style="text-align: left;">
                <h3><i class="fas fa-file-alt"></i> Pipeline</h3>
                
                <img src="assets/metricanything/pipe.jpeg" alt="Performance Comparison Chart" style="width: 100%; height: auto; margin-top: 0px; border-radius: 8px;">
                <p><strong>Overview of Metric Anything.</strong> (I) We aggregate diverse open-source 3D data into per-pixel metric depth maps, forming a ~20M image–depth dataset captured by over 10,000 cameras across heterogeneous scenes. (II) Sparse Metric Prompts, generated by randomly masking depth maps, provide a minimal interface that decouples spatial reasoning from sensor and camera biases, enabling metric depth learning from noisy, heterogeneous sources. (III) The pretrained model and its distilled prompt-free student generalize robustly across multiple downstream tasks, revealing a clear scaling trend and establishing a solid foundation for versatile, data-driven metric perception.</p>
            </div>
        </div>
    </section>


            <!-- Results -->
    <section id="results" class="results-section">
        <div class="container">
            <h2 class="section-title">Results</h2>

            <div class="results-list">
                
                <!-- Result Item 1: Real-world Application -->
                <div class="result-item">
                    <div class="result-info">
                        <h3>Video Demo on Real-world Application in a Zero-shot Setting</h3>
                        <p>
                            <!-- xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx -->
                        </p>
                    </div>
                    <div class="result-video-small">
                        <video style="width: 100%; height: auto; display: block;" playsinline muted loop controls class="app-video lazy-video" preload="metadata" data-src="assets/video/ready/4-ad.mp4">
                            <source data-src="assets/video/ready/4-ad.mp4" type="video/mp4">
                            Your browser does not support video playback.
                        </video>
                    </div>
                </div>

                <!-- Result Item 2: Blind spot completion (这里是你要修改的核心部分) -->
                <div class="result-item">
                    <div class="result-info">
                        <h3>Blind spot completion test for left and right views uncovered by LiDAR</h3>
                        <p>
                            <!-- xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx -->
                            
                            <br><span style="color:#888; font-size: 0.9em;">(Drag the slider to compare)</span>
                        </p>
                    </div>

                    <!-- 轮播组件开始 -->
                    <div class="analysis-carousel">
                        <div class="carousel-container">
                            
                            <!-- 左按钮 -->
                            <button class="carousel-btn prev-btn" onclick="changeAnalysis(-1)">
                                <i class="fas fa-chevron-left"></i>
                            </button>

                            <!-- 轮播内容区域 -->
                            <div class="carousel-content">

                                <!-- Slide 1 -->
                                <!-- <div class="analysis-slide active">
                                    <div style="position: relative;">
                                        <video class="video" width="100%" id="comp_1" loop playsinline autoplay muted 
                                            src="assets/video/ready/comparison-left-1.mp4" 
                                            onplay="resizeAndPlay(this)" 
                                            style="height: 0px; opacity: 0;">
                                        </video>
                                        <canvas height="0" class="videoMerge" id="comp_1Merge"></canvas>
                                    </div>
                                </div> -->

                                <!-- Slide 2 -->
                                <!-- <div class="analysis-slide">
                                    <div style="position: relative;">
                                        <video class="video" width="100%" id="comp_2" loop playsinline autoplay muted 
                                            src="assets/video/ready/comparison-right-1.mp4" 
                                            onplay="resizeAndPlay(this)" 
                                            style="height: 0px; opacity: 0;">
                                        </video>
                                        <canvas height="0" class="videoMerge" id="comp_2Merge"></canvas>
                                    </div>
                                </div> -->

                                <!-- Slide 3 -->
                                <!-- <div class="analysis-slide">
                                    <div style="position: relative;">
                                        <video class="video" width="100%" id="comp_3" loop playsinline autoplay muted 
                                            src="assets/video/ready/comparison-left-2.mp4" 
                                            onplay="resizeAndPlay(this)" 
                                            style="height: 0px; opacity: 0;">
                                        </video>
                                        <canvas height="0" class="videoMerge" id="comp_3Merge"></canvas>
                                    </div>
                                </div> -->

                                <!-- Slide 4 -->
                                <div class="analysis-slide">
                                    <div style="position: relative;">
                                        <video class="video" width="100%" id="comp_4" loop playsinline autoplay muted 
                                            src="assets/video/ready/comparison-right-2.mp4" 
                                            onplay="resizeAndPlay(this)" 
                                            style="height: 0px; opacity: 0;">
                                        </video>
                                        <canvas height="0" class="videoMerge" id="comp_4Merge"></canvas>
                                    </div>
                                </div>

                            </div> <!-- End .carousel-content -->

                            <button class="carousel-btn next-btn" onclick="changeAnalysis(1)">
                                <i class="fas fa-chevron-right"></i>
                            </button>
                        </div>

                        <!-- <div class="carousel-indicators">
                            <span class="indicator active" onclick="setAnalysis(0)"></span>
                            <span class="indicator" onclick="setAnalysis(1)"></span>
                            <span class="indicator" onclick="setAnalysis(2)"></span>
                            <span class="indicator" onclick="setAnalysis(3)"></span>
                        </div> -->
                    </div> 
                </div>

                <!-- Result Item 3: Robustness (Rainy/Night) -->
                <div class="result-item">
                    <div class="result-info">
                        <h3>Robustness under Environmental Degradation</h3>
                        <p class="text-large">
                            In rainy environment, our model utilizes visual information to overcome significant LiDAR degradation, ensuring accurate depth super-resolution and completion as demonstrated in real-world vehicle testing.
                        </p>
                    </div>

                    <div class="image-with-title">
                        <div class="result-image-large">
                            <img src="./assets/metricanything/supp_ad_rainy_env_dc.jpeg" alt="Robustness under rainy environment" loading="lazy">
                        </div>
                        <h4 class="image-title">Robustness under <span class="highlight-rainy">rainy</span> environment</h4>
                    </div>

                    <div class="result-info">
                        <p class="text-large">
                        In low-light real-world deployments, our model demonstrates remarkable robustness and achieves generalizable novel view synthesis by predicting 3DGS parameters.
                        </p> 
                    </div>
                    
                    <div class="image-with-title">
                        <div class="result-image-large">
                            <img src="./assets/metricanything/supp_ad_night_dc.jpeg" alt="Robustness under night environment" loading="lazy">
                        </div>
                        <h4 class="image-title">Robustness under <span class="highlight-night">night</span> environment</h4>
                    </div>
                </div>

                <!-- Result Item 4: Spatial Understanding -->
                <div class="result-item">
                    <div class="result-info">
                        <h3>Spatial Understanding of MLLMs</h3>
                        <p class="text-large">
                            Our model achieves robust performance on the VSI-Bench spatial reasoning tasks, proving that its learned representations can significantly improve existing VLMs in critical areas such as navigation, object sizing, and route planning.
                        </p>
                    </div>
                    <div class="result-video-small">
                        <video playsinline muted autoplay loop class="app-video lazy-video" preload="metadata" data-src="assets/video/mllm.mov">
                            <source data-src="assets/video/mllm.mp4" type="video/mp4">
                            Your browser does not support video playback.
                        </video>
                    </div>
                    <div class="result-image-large">
                        <img src="./assets/metricanything/mllm.png" alt="Spatial Understanding of MLLMs" loading="lazy">
                    </div>
                </div>

                <!-- Result Item 5: VLA planning -->
                <div class="result-item">
                    <div class="result-info">
                        <h3>VLA planning</h3>
                        <p class="text-large">
                            By distilling depth perception capabilities into a VLA model to predict depth tokens, our approach achieves superior manipulation performance on the LIBERO benchmark compared to Depth Anything V2, without requiring depth inputs at test time.
                        </p>
                    </div>
                    <div class="result-video-small">
                        <video playsinline muted autoplay loop class="app-video lazy-video" preload="metadata" data-src="assets/video/vla.mov">
                            <source data-src="assets/video/vla.mov" type="video/mp4">
                            Your browser does not support video playback.
                        </video>
                    </div>
                    <div class="result-image-large result-image-medium">
                        <img src="./assets/metricanything/vla.png" alt="VLA planning" loading="lazy">
                    </div>
                </div>

            </div> <!-- End .results-list -->
        </div> <!-- End .container -->
    </section>


    <!-- Comparison -->
    <section id="comparison" class="results-section">
        <div class="container">
            <h2 class="section-title">Comparison</h2>
            <div class="results-list">
                <!-- Robustness under Environmental Degradation -->
                <div class="result-item">
                    <div class="result-info">
                        <h3>Zero-Shot Depth Super-Resolution and Completion</h3>
                        <p class="text-large">
                        </p>
                    </div>

                    <div class="image-with-title">
                        <div class="result-image-large">
                            <img src="./assets/metricanything/table.png" alt="Robustness under night environment" loading="lazy">
                        </div>
                        <!-- <h4 class="image-title">Robustness under <span class="highlight-night">night</span> environment</h4> -->
                    </div>

                    <div class="image-with-title">
                        <div class="result-image-large">
                            <img src="./assets/metricanything/comp.png" alt="Robustness under rainy environment" loading="lazy">
                        </div>
                        <!-- <h4 class="image-title">Visualization of Depth SR and Completion.</h4> -->
                    </div>
                </div>
            </div>
        </div>
    </section>




    <!-- Abilities -->

    <section id="interactive-examples" class="interactive-results">
        <div class="container">
          <h2 class="section-title">Interactive Demos</h2>
          
          <!-- Main Display Area -->
          <div class="main-display-container">
            <!-- Loading Indicator for iframe -->
            <div class="iframe-loader hidden" id="iframeLoader">
              <div class="loader-spinner"></div>
              <div class="loader-text">Loading interactive demo...</div>
            </div>
            <iframe 
              id="mainIframe" 
              class="main-iframe loaded"
              src="glb-viewer.html?src=assets/interactive/01/mesh.glb">
            </iframe>
          </div>
          
          <!-- Thumbnail Gallery -->
          <div class="thumbnail-gallery">
            <!-- Local Interactive Examples -->
            <div class="thumbnail-item active" 
                data-src="glb-viewer.html?src=assets/interactive/01/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/01/image.jpg" alt="Example 1" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/02/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/02/image.jpg" alt="Example 2" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/03/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/03/image.jpg" alt="Example 3" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/04/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/04/image.jpg" alt="Example 4" onerror="this.src='assets/placeholder.svg'">
            </div>
            
            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/more/robo-arm/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/more/robo-arm/image.jpg" alt="Example 5" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/more/006/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/more/006/image.jpg" alt="Example 6" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/07/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/07/image.jpg" alt="Example 7" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/08/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/08/image.jpg" alt="Example 8" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/more/001/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/more/001/image.jpg" alt="Example 9" onerror="this.src='assets/placeholder.svg'">
            </div>

            <div class="thumbnail-item" 
                data-src="glb-viewer.html?src=assets/interactive/more/002/mesh.glb"
                onclick="switchIframe(this)">
              <img src="assets/interactive/more/002/image.jpg" alt="Example 10" onerror="this.src='assets/placeholder.svg'">
            </div>
          </div>
        </div>
    </section>





    <!-- Citation -->
    <section id="citation" class="citation">
        <div class="container">
            <h2 class="section-title">Citation</h2>
            <div class="citation-box">
                <pre><code>
@article{metricanything2026,
    title={MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources},
    author={Metric Anything Team},
    journal={arXiv preprint},
    year={2026}
}</code></pre>
            </div>
        </div>
    </section>

    <script src="script.js"></script>
    
    <!-- 备用：确保 setAbility 函数可用 -->
    <script>
        // 如果 script.js 加载失败，提供一个备用函数
        if (typeof window.setAbility === 'undefined') {
            console.error('警告：script.js 中的 setAbility 未加载，使用备用函数');
            window.setAbility = function(index) {
                console.log('使用备用 setAbility:', index);
                const slides = document.querySelectorAll('.abilities-tabs .application-slide');
                const buttons = document.querySelectorAll('.abilities-tabs .indicator');
                
                // 移除所有 active
                slides.forEach(s => s.classList.remove('active'));
                buttons.forEach(b => b.classList.remove('active'));
                
                // 添加新的 active
                if (slides[index]) slides[index].classList.add('active');
                if (buttons[index]) buttons[index].classList.add('active');
            };
        } else {
            console.log('✓ setAbility 函数已从 script.js 正确加载');
        }
    </script>
</body>
</html>
